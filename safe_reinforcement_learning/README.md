## Introduction to Safe RL

We have seen recent amazing evolution of RL algorithms and its applications, such as the combination of Deep Neural Network and RL for playing game of Atari 2600 ([DQN Mnih et al,. 2015](https://www.nature.com/articles/nature14236)). Yet, we might still wonder if it is actually safe enough to interact with human beings. Furthermore, particularly researchers might wonder if they safely conduct the experiments with RL approaches on some physical applications, e.g., mobile robot walking along with the pedestrians on the road. In these situations, simply saying, we have to prioritise the safety to the optimality, and ideally the learning agent can learn the policy which appropriately compromise both the safety and the performance. In this domain, there are already plenty of approaches examined by researches though, there are still huge room for the further improvements. So in this repo, i have stored my reviewing notes for my research purpose.



## Notes

1. [A Comprehensive Survey on Safe Reinforcement Learning by Javier Garcia and Fernando Fernandez in 2015](https://github.com/Rowing0914/Reinforcement_Learning/blob/master/safe_reinforcement_learning/A_comprehensive_survey_Safe_RL/README.md)
2. [Tutorial_on_Safe_Reinforcement_Learning by Felix Berkenkamp, Andreas Krause](https://github.com/Rowing0914/Reinforcement_Learning/tree/master/safe_reinforcement_learning/Tutorial_on_Safe_Reinforcement_Learning/README.md)



## To-do

- finish summarising `A Comprehensive Survey on Safe Reinforcement Learning` and `Tutorial_on_Safe_Reinforcement_Learning`.